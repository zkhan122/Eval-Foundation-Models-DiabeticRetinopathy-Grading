{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00b678f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c97ff7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.expand_frame_repr', False)  # Don't wrap to multiple lines\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80b2b9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_file_extensions = [\"jpg\", \"jpeg\", \"png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9849be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedDRDataSet(Dataset):\n",
    "\n",
    "    def __init__(self, \n",
    "            root_directories: Dict[str, str],\n",
    "            split: str=\"train\", \n",
    "            img_transform: Optional[transforms.Compose] = None,\n",
    "            label_transform: Optional[transforms.Compose] = None):\n",
    "        \n",
    "        self.root_directories = root_directories # dictionary containing dataset name : dataset path\n",
    "        self.split = split \n",
    "        self.img_transform = img_transform\n",
    "        self.label_transform = label_transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        # to track which dataset each image comes from\n",
    "        self.sources = []\n",
    "\n",
    "        if \"MFIDDR\" in self.root_directories:\n",
    "            self.load_MFIDDR()\n",
    "        # if \"idrid\" in self.root_directories:\n",
    "        #     self.load_IDRID()\n",
    "        # if \"deepdrid\" in self.root_directories:\n",
    "        #     self.load_DEEPDRID()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.labels\n",
    "    \n",
    "    def get_sources(self):\n",
    "        return self.sources\n",
    "    \n",
    "    def load_MFIDDR(self):\n",
    "        MFIDDR_ROOT = Path(self.root_directories[\"MFIDDR\"])\n",
    "\n",
    "        print(f\"MFIDDR_ROOT: {MFIDDR_ROOT}\")\n",
    "        print(f\"MFIDDR_ROOT exists: {MFIDDR_ROOT.exists()}\")\n",
    "\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            image_directory = MFIDDR_ROOT / \"sample\" / \"train-examples\"\n",
    "            print(image_directory)\n",
    "        else:\n",
    "            image_directory = MFIDDR_ROOT / \"sample\" / \"test-examples\"\n",
    "\n",
    "        if not image_directory.exists():\n",
    "            print(f\"ERROR: MFIDDR path was not found at {image_directory}\")\n",
    "\n",
    "        for image_file_path in os.listdir(image_directory):\n",
    "            filename, file_extension = os.path.splitext(image_file_path)\n",
    "            # removing the dot before the file extension as we already have defined and making lower\n",
    "            file_extension = file_extension.lstrip('.').lower()\n",
    "            if file_extension in valid_file_extensions:\n",
    "                self.image_paths.append(str(image_directory / image_file_path))\n",
    "                self.labels.append(filename)\n",
    "                self.sources.append(\"MFIDDR\")\n",
    "\n",
    "    def load_labels_from_csv(self, csv_paths_dict: Dict[str, str]):\n",
    "        if len(self.labels) == 0:\n",
    "            self.labels = [None] * len(self.image_paths)\n",
    "        \n",
    "        for dataset_name, csv_path in csv_paths_dict.items():\n",
    "            # checking if the csv file exists\n",
    "            if not os.path.exists(csv_path):\n",
    "                print(f\"FileNotFoundError: CSV not found at {csv_path}\")\n",
    "                continue\n",
    "        \n",
    "        # loading the csv\n",
    "        labels_df = pd.read_csv(csv_path)\n",
    "        print(f\"Loaded labels for {dataset_name}: {len(labels_df)} rows\")\n",
    "\n",
    "        print(labels_df.tail(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19dcf799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFIDDR_ROOT: D:\\Zayaan\\D_git\\Eval-Foundation-Models-DiabeticRetinopathy-Grading\\datasets\\MFIDDR\n",
      "MFIDDR_ROOT exists: True\n",
      "D:\\Zayaan\\D_git\\Eval-Foundation-Models-DiabeticRetinopathy-Grading\\datasets\\MFIDDR\\sample\\train-examples\n",
      "Loaded labels for MFIDDR: 6462 rows\n",
      "                       id  level  age                     id1                     id2                     id3                     id4\n",
      "6457   3324_15236635_left      4   40   3324_15236635_left_05   3324_15236635_left_06   3324_15236635_left_07   3324_15236635_left_08\n",
      "6458  3418_57689745_right      4   44  3418_57689745_right_01  3418_57689745_right_02  3418_57689745_right_03  3418_57689745_right_04\n",
      "6459   3418_57689745_left      4   44   3418_57689745_left_05   3418_57689745_left_06   3418_57689745_left_07   3418_57689745_left_08\n",
      "6460  3441_70906177_right      4   53  3441_70906177_right_01  3441_70906177_right_02  3441_70906177_right_03  3441_70906177_right_04\n",
      "6461   3441_70906177_left      4   53   3441_70906177_left_05   3441_70906177_left_06   3441_70906177_left_07   3441_70906177_left_08\n",
      "TRAIN DATASET LENGTH: 48\n",
      "Labels ['20_28096452_left_05', '20_28096452_left_06', '20_28096452_left_07', '20_28096452_left_08', '20_28096452_right_01', '20_28096452_right_02', '20_28096452_right_03', '20_28096452_right_04', '21_07586213_left_05', '21_07586213_left_06', '21_07586213_left_07', '21_07586213_left_08', '21_07586213_right_01', '21_07586213_right_02', '21_07586213_right_03', '21_07586213_right_04', '22_50677653_left_05', '22_50677653_left_06', '22_50677653_left_07', '22_50677653_left_08', '22_50677653_right_01', '22_50677653_right_02', '22_50677653_right_03', '22_50677653_right_04', '4_24492991_left_05', '4_24492991_left_06', '4_24492991_left_07', '4_24492991_left_08', '4_24492991_right_01', '4_24492991_right_02', '4_24492991_right_03', '4_24492991_right_04', '5_04780413_left_05', '5_04780413_left_06', '5_04780413_left_07', '5_04780413_left_08', '5_04780413_right_01', '5_04780413_right_02', '5_04780413_right_03', '5_04780413_right_04', '6_15582927_left_05', '6_15582927_left_06', '6_15582927_left_07', '6_15582927_left_08', '6_15582927_right_01', '6_15582927_right_02', '6_15582927_right_03', '6_15582927_right_04']\n",
      "Sources ['MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR', 'MFIDDR']\n"
     ]
    }
   ],
   "source": [
    "# In a Jupyter notebook __file__ is not defined, fall back to the current working directory\n",
    "\n",
    "\n",
    "root_directories = {\n",
    "    \"MFIDDR\": \"D:/Zayaan/D_git/Eval-Foundation-Models-DiabeticRetinopathy-Grading/datasets/MFIDDR\"\n",
    "}\n",
    "\n",
    "train_transformations = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = CombinedDRDataSet(root_directories=root_directories, split=\"train\", img_transform=train_transformations)\n",
    "\n",
    "# loading csv_paths\n",
    "train_csv_paths = {\n",
    "    \"MFIDDR\": f\"{root_directories['MFIDDR']}/sample/train_fourpic_label.csv\"\n",
    "}\n",
    "\n",
    "train_dataset.load_labels_from_csv(train_csv_paths)\n",
    "\n",
    "print(\"TRAIN DATASET LENGTH:\", train_dataset.__len__()) # 11/11/25 len is 0 for both hence there is error in data preprocessing \n",
    "\n",
    "print(\"Labels\", train_dataset.get_labels())\n",
    "print(\"Sources\", train_dataset.get_sources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea7912a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
