{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yraoDLAe7y5p"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "FOLDER_NAME = \"Eval-Foundation-Models-DiabeticRetinopathy-Grading\"\n",
        "\n",
        "# 1. Define the Main Project Base (The parent of both src and datasets)\n",
        "PROJECT_BASE_PATH = os.path.join(\"/content/drive/MyDrive\", FOLDER_NAME)\n",
        "\n",
        "# 2. Define the specific sub-paths\n",
        "SRC_PATH = os.path.join(PROJECT_BASE_PATH, \"src\")\n",
        "DATA_DIR = os.path.join(PROJECT_BASE_PATH, \"datasets\")\n",
        "\n",
        "# --- SETUP ---\n",
        "if os.path.exists(SRC_PATH):\n",
        "    # Add 'src' to sys.path for imports\n",
        "    if SRC_PATH not in sys.path:\n",
        "        sys.path.append(SRC_PATH)\n",
        "\n",
        "    # Change working directory to 'src' (keeps relative imports working internally)\n",
        "    os.chdir(SRC_PATH)\n",
        "\n",
        "    print(f\"System Path Updated.\")\n",
        "    print(f\"Working Directory: {os.getcwd()}\")\n",
        "\n",
        "    # Verify Datasets path\n",
        "    if os.path.exists(DATA_DIR):\n",
        "        print(f\"Dataset Directory Found: {DATA_DIR}\")\n",
        "        # List the contents to confirm (IDRiD, DeepDR, etc.)\n",
        "        print(f\"Contents: {os.listdir(DATA_DIR)}\")\n",
        "    else:\n",
        "        print(f\"WARNING: Dataset path not found at: {DATA_DIR}\")\n",
        "else:\n",
        "    print(f\"he project path does not exist: {PROJECT_BASE_PATH}\")"
      ],
      "metadata": {
        "id": "kMvplCwHB0eM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install timm==0.9.10\n",
        "!pip install peft"
      ],
      "metadata": {
        "id": "C1WbPnqcEt8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models.RETFound_MAE import models_vit\n",
        "from models.RETFound_MAE.util import pos_embed\n",
        "from timm.models.layers import trunc_normal_\n",
        "import torchvision\n",
        "from data_processing.dataloader import load_idrid_grading_labels\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from data_processing.dataset import CombinedDRDataSet\n",
        "from utilities.utils import identity_transform, show_images, train_one_epoch, validate\n",
        "from utilities.create_split import extract_for_split\n",
        "from hparams.hparams import NUM_CLASSES,BATCH_SIZE, NUM_EPOCHS, LEARNING_RATE, NUM_WORKERS, DEVICE\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim"
      ],
      "metadata": {
        "id": "jRPqmTfrEO59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data initialization"
      ],
      "metadata": {
        "id": "sHMhPIVI7z2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_directories = {\n",
        "    \"DEEPDRID\": f\"{DATA_DIR}/DeepDRiD\",\n",
        "    \"IDRID\": f\"{DATA_DIR}/IDRID\",\n",
        "    \"MESSIDOR\": f\"{DATA_DIR}/MESSIDOR\",\n",
        "    \"MFIDDR\": f\"{DATA_DIR}/MFIDDR\", # only use for test if necessary\n",
        "}\n",
        "\n",
        "MESSIDOR_BASE_PATH = root_directories[\"MESSIDOR\"]\n",
        "# The SOURCE directory containing the images you want to split (80% will remain here for training):\n",
        "SOURCE_DIR = os.path.join(MESSIDOR_BASE_PATH, \"messidor-2\", \"messidor-2\", \"preprocess\")\n",
        "# The DESTINATION directory where the 20% test images will be moved:\n",
        "DESTINATION_DIR = os.path.join(MESSIDOR_BASE_PATH, \"messidor-2\", \"messidor-2\", \"test\")\n",
        "TEST_FRACTION = 0.2\n",
        "\n",
        "print(\"Starting Data Split for MESSIDOR...\")\n",
        "extract_for_split(SOURCE_DIR, DESTINATION_DIR, TEST_FRACTION)\n",
        "print(\"MESSIDOR split complete.\")"
      ],
      "metadata": {
        "id": "o1O1JD7e3KBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transformations = transforms.Compose([\n",
        "    transforms.Resize((192, 192)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transformations = transforms.Compose([\n",
        "    transforms.Resize((192, 192)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = CombinedDRDataSet(root_directories=root_directories, split=\"train\", img_transform=train_transformations, label_transform=identity_transform)\n",
        "# test_dataset = CombinedDRDataSet(root_directories=root_directories, split=\"test\", img_transform=test_transformations)\n",
        "\n",
        "\n",
        "print(\"Labels\", train_dataset.get_labels())\n",
        "\n",
        "# loading csv_paths (removed MFIDDR as too little samples , but possibly can use in testing)\n",
        "train_csv_paths = {\n",
        "    \"IDRID\": f\"{root_directories['IDRID']}/B-Disease-Grading/Disease-Grading/2-Groundtruths/IDRiD_Disease_Grading_Training_Labels.csv\",\n",
        "    \"DEEPDRID\": f\"{root_directories['DEEPDRID']}/regular_fundus_images/regular-fundus-training/regular-fundus-training.csv\",\n",
        "    \"MESSIDOR\": f\"{root_directories['MESSIDOR']}/messidor_data.csv\",\n",
        "}\n",
        "\n",
        "# test_csv_paths = {\n",
        "#     \"IDRID\": f\"{root_directories['IDRID']}/B-Disease-Grading/Disease-Grading/2-Groundtruths/IDRiD_Disease_Grading_Testing_Labels.csv\",\n",
        "#     \"DEEPDRID\": f\"{root_directories['DEEPDRID']}/regular_fundus_images/regular-fundus-validation/regular-fundus-validation.csv\",\n",
        "#     \"MFIDDR\": f\"{root_directories['MFIDDR']}/sample/test_fourpic_label.csv\"\n",
        "# }\n",
        "\n",
        "train_labels = train_dataset.load_labels_from_csv(train_csv_paths)\n",
        "# train_dataset.load_labels_from_csv(test_csv_paths)\n",
        "\n",
        "\n",
        "# print(\"TRAIN DATASET LENGTH:\", train_dataset.__len__()) # 11/11/25 len is 0 for both hence there is error in data preprocessing\n",
        "# print(\"TEST DATASET LENGTH:\", test_dataset.__len__())\n",
        "\n",
        "\n",
        "\n",
        "# printing dataset statistics\n",
        "print(\"Training Set Statistics:\")\n",
        "print(train_dataset.get_dataset_statistics())\n",
        "\n",
        "\n",
        "# print(\"\\nTest Set Statistics:\")\n",
        "# print(test_dataset.get_dataset_statistics())\n",
        "\n",
        "# --- FIX: Set num_workers=0 to prevent freezing on Drive ---\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "print(train_loader.batch_size)\n",
        "\n",
        "# test_loader = DataLoader(\n",
        "#     test_dataset,\n",
        "#     batch_size=32,\n",
        "#     shuffle=False,\n",
        "#     num_workers=4\n",
        "# )\n",
        "\n",
        "\n",
        "print(train_loader)\n",
        "\n",
        "# checking inside dataset\n",
        "# for idx in range(len(train_dataset)):\n",
        "#     image, label, metadata = train_dataset[idx]\n",
        "#     print(f\"Image: {image} -- Label: {label} -- Metadata: {metadata}\")\n",
        "\n",
        "dataset_length = len(train_dataset)\n",
        "print(\"total samples: \", dataset_length)\n",
        "\n",
        "# show_images(train_dataset, train_labels, num_images=60, start_idx=0)\n",
        "\n",
        "# mfiddr -> idrid -> deepdrid\n",
        "# 413 idrid\n",
        "# 1661 total\n",
        "\n",
        "print(f\"\\nTrain batches: {len(train_loader)}\")\n",
        "# print(f\"Test batches: {len(test_loader)}\")\n"
      ],
      "metadata": {
        "id": "_z7u1aEK7zgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RETFound model intialization"
      ],
      "metadata": {
        "id": "wPpU7-Xa8LEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(train_dataset, train_labels, num_images=30, start_idx=len(train_dataset)-200)"
      ],
      "metadata": {
        "id": "wnyv77KVICe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "# show_images(train_dataset, train_labels, num_images=60, start_idx=0)\n",
        "\n",
        "# mfiddr -> idrid -> deepdrid\n",
        "# 413 idrid\n",
        "# 1661 total\n",
        "\n",
        "print(f\"\\nTrain batches: {len(train_loader)}\")\n",
        "# print(f\"Test batches: {len(test_loader)}\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Initializing RETFound Model\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "model = models_vit.__dict__[\"vit_large_patch16\"](\n",
        "    num_classes=NUM_CLASSES,\n",
        "    drop_path_rate=0.2,\n",
        "    global_pool=True\n",
        ")\n",
        "\n",
        "checkpoint_path = f\"{SRC_PATH}/models/RETFound_MAE/weights/RETFound_cfp_weights.pth\"\n",
        "print(f\"Loading pretrained weights from: {checkpoint_path}\")\n",
        "\n",
        "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=False)\n",
        "checkpoint_model = checkpoint[\"model\"]\n",
        "state_dict = model.state_dict()\n",
        "\n",
        "# removing head weights (as they dont match number of classes for severity grading 0-4)\n",
        "for k in [\"head.weight\", \"head.bias\"]:\n",
        "    if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
        "        print(f\"Removing key {k} from pretrained checkpoint (shape mismatch)\")\n",
        "        del checkpoint_model[k]\n",
        "\n",
        "pos_embed.interpolate_pos_embed(model, checkpoint_model)\n",
        "\n",
        "# Loading the weights\n",
        "msg = model.load_state_dict(checkpoint_model, strict=False)\n",
        "print(f\"Missing keys: {msg.missing_keys}\")\n",
        "print(f\"Unexpected keys: {msg.unexpected_keys}\")\n",
        "\n",
        "# verifying we're only missing the classification head\n",
        "assert set(msg.missing_keys) == {\"head.weight\", \"head.bias\", \"fc_norm.weight\", \"fc_norm.bias\"}\n",
        "\n",
        "# initializing the new classification head\n",
        "trunc_normal_(model.head.weight, std=2e-5)\n",
        "\n",
        "print(\"\\nWrapping model with LoRA adapters...\")\n",
        "peft_config = LoraConfig(\n",
        "    r=16,                  # rank\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"qkv\"], # target attention layers in ViT\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    modules_to_save=[\"head\", \"fc_norm\"] # keeping classification head and norm trainable\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "# param count\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.05)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n"
      ],
      "metadata": {
        "id": "M4MhJ9QLDDJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "r0Ao80tR7XkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Starting Training\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        model, train_loader, criterion, optimizer, DEVICE, epoch\n",
        "    )\n",
        "\n",
        "    # Validate\n",
        "    # val_loss, val_acc = validate(model, test_loader, criterion)\n",
        "\n",
        "    # lr update\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
        "    # print(f\"  Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% \")\n",
        "    print(f\"  Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "    # Saving best model\n",
        "    # if val_acc > best_val_acc:\n",
        "    #     best_val_acc = val_acc\n",
        "    #     print(f\"  âœ“ New best validation accuracy: {val_acc:.2f}%\")\n",
        "    #     torch.save({\n",
        "    #         'epoch': epoch,\n",
        "    #         'model_state_dict': model.state_dict(),\n",
        "    #         'optimizer_state_dict': optimizer.state_dict(),\n",
        "    #         'val_acc': val_acc,\n",
        "    #         'val_loss': val_loss,\n",
        "    #     }, 'best_retfound_model.pth')\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Training Complete!\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "li3jbJ4A7Wy5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}